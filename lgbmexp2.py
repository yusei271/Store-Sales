import numpy as np
import pandas as pd
import lightgbm as lgb
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_log_error

# ðŸ“Œ ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
def load_data():
    train = pd.read_csv("train.csv", parse_dates=["date"])
    test = pd.read_csv("test.csv", parse_dates=["date"])
    stores = pd.read_csv("stores.csv")
    oil = pd.read_csv("oil.csv", parse_dates=["date"])
    holidays = pd.read_csv("holidays_events.csv", parse_dates=["date"])
    transactions = pd.read_csv("transactions.csv", parse_dates=["date"])
    
    return train, test, stores, oil, holidays, transactions

df_train, df_test, df_stores, df_oil, df_holidays, df_transactions = load_data()

# ðŸ“Œ ç¥æ—¥ãƒ‡ãƒ¼ã‚¿ã¯ Nationalï¼ˆå…¨å›½ï¼‰ã®ã¿ã‚’ä½¿ç”¨
df_holidays = df_holidays[df_holidays["locale"] == "National"]

# ðŸ“Œ ã‚«ãƒ©ãƒ åã®æ•´ç†
df_stores.rename(columns={"type": "type_store"}, inplace=True)
df_holidays.rename(columns={"type": "type_holiday"}, inplace=True)

# ðŸ“Œ ãƒ‡ãƒ¼ã‚¿ã®çµåˆ
def merge_data(df):
    df = df.merge(df_stores, on="store_nbr", how="left")
    df = df.merge(df_oil, on="date", how="left")
    df = df.merge(df_transactions, on=["date", "store_nbr"], how="left")
    df = df.merge(df_holidays, on="date", how="left")
    return df

df_train = merge_data(df_train)
df_test = merge_data(df_test)

# ðŸ“Œ æ¬ æå€¤ã®è£œå®Œ
df_train["dcoilwtico"].fillna(df_train["dcoilwtico"].mean(), inplace=True)
df_test["dcoilwtico"].fillna(df_test["dcoilwtico"].mean(), inplace=True)
df_train["transactions"].fillna(0, inplace=True)
df_test["transactions"].fillna(0, inplace=True)

# ðŸ“Œ æ—¥ä»˜é–¢é€£ã®ç‰¹å¾´é‡
for df in [df_train, df_test]:
    df["day_of_week"] = df["date"].dt.dayofweek
    df["month"] = df["date"].dt.month
    df["year"] = df["date"].dt.year
    df["is_weekend"] = (df["day_of_week"] >= 5).astype(int)

# ðŸ“Œ ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
categorical_columns = ["store_nbr", "family", "city", "state", "locale", "locale_name", "description", "transferred"]
label_encoders = {}

for col in categorical_columns:
    le = LabelEncoder()
    df_train[col] = le.fit_transform(df_train[col].astype(str))
    df_test[col] = le.transform(df_test[col].astype(str))
    label_encoders[col] = le

# ðŸ“Œ One-Hot Encodingï¼ˆåº—èˆ—ã‚¿ã‚¤ãƒ— & ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ï¼‰
df_train = pd.get_dummies(df_train, columns=["type_store", "cluster"], drop_first=True)
df_test = pd.get_dummies(df_test, columns=["type_store", "cluster"], drop_first=True)

# ðŸ“Œ æ™‚ç³»åˆ—ç‰¹å¾´é‡ã®ä½œæˆ
for lag in [7, 14, 30]:
    df_train[f"lag_{lag}"] = df_train["sales"].shift(lag)

# NaN ã‚’åŸ‹ã‚ã‚‹
df_train.fillna(0, inplace=True)
df_test.fillna(0, inplace=True)

# ðŸ“Œ ç¥æ—¥ãƒ•ãƒ©ã‚°ã®ä½œæˆ
df_train["is_holiday"] = df_train["type_holiday"].apply(lambda x: 1 if x == "Holiday" else 0).fillna(0)
df_test["is_holiday"] = df_test["type_holiday"].apply(lambda x: 1 if x == "Holiday" else 0).fillna(0)

# ðŸ“Œ å¤–ã‚Œå€¤ã®é™¤åŽ»ï¼ˆIQRã‚’ä½¿ç”¨ï¼‰
Q1 = df_train["sales"].quantile(0.25)
Q3 = df_train["sales"].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
df_train = df_train[(df_train["sales"] >= lower_bound) & (df_train["sales"] <= upper_bound)]

# ðŸ“Œ é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤
df_train.drop_duplicates(inplace=True)
df_test.drop_duplicates(inplace=True)

# ðŸ“Œ èª¬æ˜Žå¤‰æ•°ã¨ç›®çš„å¤‰æ•°ã‚’åˆ†ã‘ã‚‹
TARGET = "sales"
features = df_train.drop(columns=[TARGET, "date", "type_holiday"]).columns

X = df_train[features]
y = np.log1p(df_train[TARGET])  # ðŸ’¡ log(1+x) ã‚’é©ç”¨

# ðŸ“Œ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)

# ðŸ“Œ LightGBM ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå½¢å¼ã«å¤‰æ›
train_data = lgb.Dataset(X_train, label=y_train)
valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)

# âœ… **ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªãƒƒã‚¯ï¼ˆRMSLEï¼‰ã‚’å®šç¾©**
def rmsle_eval(y_pred, dataset):
    y_true = dataset.get_label()
    return 'rmsle', np.sqrt(mean_squared_log_error(y_true, np.maximum(y_pred, 0))), False

params = {
    "objective": "regression",
    "metric": "rmse",
    "learning_rate": 0.05,
    "num_leaves": 31,
    "max_depth": 10,
    "subsample": 0.8,
    "colsample_bytree": 0.8
}

# ðŸ“Œ LightGBM ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
model = lgb.train(
    params,
    train_data,
    num_boost_round=1000,
    valid_sets=[train_data, valid_data],  # âœ… å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚’æŒ‡å®š
    valid_names=["train", "valid"],  # âœ… ãƒ­ã‚°è¡¨ç¤ºã®ãŸã‚ã®åå‰
    feval=rmsle_eval,  # âœ… ã“ã“ã§ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’è¿½åŠ ï¼
    callbacks=[
        lgb.early_stopping(50),  # âœ… `early_stopping_rounds` ã®ä»£ã‚ã‚Šã« `callbacks` ã‚’ä½¿ç”¨
        lgb.log_evaluation(100)  # âœ… 100å›žã”ã¨ã«ãƒ­ã‚°ã‚’è¡¨ç¤º
    ]
)

# ðŸ“Œ äºˆæ¸¬ï¼†è©•ä¾¡ï¼ˆRMSLE ã‚’æœ€çµ‚ç¢ºèªï¼‰
# âœ… ãƒ¢ãƒ‡ãƒ«ãŒäºˆæ¸¬ã—ãŸå€¤ã‚’ `expm1` ã§å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™
y_pred = np.expm1(model.predict(X_valid, num_iteration=model.best_iteration))

# âœ… æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚‚ `expm1` ã§å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™
y_valid_orig = np.expm1(y_valid)

# âœ… è² ã®å€¤ã‚’0ã«è£œæ­£
y_pred = np.maximum(y_pred, 0)
y_valid_orig = np.maximum(y_valid_orig, 0)

# âœ… RMSLE ã®å†è¨ˆç®—ï¼ˆæ­£ã—ã„ã‚¹ã‚±ãƒ¼ãƒ«ã§ï¼‰
rmsle = np.sqrt(mean_squared_log_error(y_valid_orig, y_pred))

print(f"âœ… LightGBM RMSLE (ä¿®æ­£å¾Œ): {rmsle:.4f}")