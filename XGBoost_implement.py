import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder

# ðŸ“Œ ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
def load_data():
    train = pd.read_csv("train.csv", parse_dates=["date"])
    test = pd.read_csv("test.csv", parse_dates=["date"])
    stores = pd.read_csv("stores.csv")
    oil = pd.read_csv("oil.csv", parse_dates=["date"])
    holidays = pd.read_csv("holidays_events.csv", parse_dates=["date"])
    transactions = pd.read_csv("transactions.csv", parse_dates=["date"])
    
    return train, test, stores, oil, holidays, transactions

df_train, df_test, df_stores, df_oil, df_holidays, df_transactions = load_data()

# ðŸ“Œ ç¥æ—¥ãƒ‡ãƒ¼ã‚¿ã¯ Nationalï¼ˆå…¨å›½ï¼‰ã®ã¿ã‚’ä½¿ç”¨
df_holidays = df_holidays[df_holidays["locale"] == "National"]

# ðŸ“Œ ã‚«ãƒ©ãƒ åã®æ•´ç†ï¼ˆ`type` ã®ç«¶åˆã‚’é˜²ãï¼‰
df_stores.rename(columns={"type": "type_store"}, inplace=True)
df_holidays.rename(columns={"type": "type_holiday"}, inplace=True)

# ðŸ“Œ ãƒ‡ãƒ¼ã‚¿ã®çµåˆ
def merge_data(df):
    df = df.merge(df_stores, on="store_nbr", how="left")
    df = df.merge(df_oil, on="date", how="left")
    df = df.merge(df_transactions, on=["date", "store_nbr"], how="left")
    df = df.merge(df_holidays, on="date", how="left")
    return df

df_train = merge_data(df_train)
df_test = merge_data(df_test)

# ðŸ“Œ æ¬ æå€¤ã®è£œå®Œï¼ˆåŽŸæ²¹ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼‰
df_train["dcoilwtico"].interpolate(inplace=True)
df_train["dcoilwtico"].fillna(df_train["dcoilwtico"].mean(), inplace=True)

df_test["dcoilwtico"].interpolate(inplace=True)
df_test["dcoilwtico"].fillna(df_test["dcoilwtico"].mean(), inplace=True)

# ðŸ“Œ æ—¥ä»˜é–¢é€£ã®ç‰¹å¾´é‡
for df in [df_train, df_test]:
    df["day_of_week"] = df["date"].dt.dayofweek  # 0=æœˆæ›œ, 6=æ—¥æ›œ
    df["month"] = df["date"].dt.month
    df["year"] = df["date"].dt.year
    df["is_weekend"] = (df["day_of_week"] >= 5).astype(int)

# ðŸ“Œ ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
le = LabelEncoder()
for df in [df_train, df_test]:
    df["store_encoded"] = le.fit_transform(df["store_nbr"])
    df["family_encoded"] = le.fit_transform(df["family"])

# ðŸ“Œ One-Hot Encodingï¼ˆåº—èˆ—ã‚¿ã‚¤ãƒ— & ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ï¼‰
df_train = pd.get_dummies(df_train, columns=["type_store", "cluster"], drop_first=False)
df_test = pd.get_dummies(df_test, columns=["type_store", "cluster"], drop_first=False)

# ðŸ“Œ æ™‚ç³»åˆ—ç‰¹å¾´é‡ã®ä½œæˆï¼ˆéŽåŽ»ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã†ï¼‰
for lag in [7, 14, 30]:
    df_train[f"lag_{lag}"] = df_train["sales"].shift(lag)
    df_train[f"rolling_mean_{lag}"] = df_train["sales"].shift(lag).rolling(window=lag).mean()

for lag in [7, 14, 30]:
    df_test[f"lag_{lag}"] = 0  # äºˆæ¸¬å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã«ã¯éŽåŽ»ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ä»®ã«ã‚¼ãƒ­ã§åŸ‹ã‚ã‚‹
    df_test[f"rolling_mean_{lag}"] = 0
df_train.fillna(0, inplace=True)  # æ¬ æå€¤ã‚’NANã‚’ã‚¼ãƒ­ã§åŸ‹ã‚ã‚‹
df_test.fillna(0, inplace=True)  

# ðŸ“Œ ç¥æ—¥ãƒ•ãƒ©ã‚°ã®ä½œæˆ
df_train["is_holiday"] = df_train["type_holiday"].apply(lambda x: 1 if x == "Holiday" else 0).fillna(0)
df_test["is_holiday"] = df_test["type_holiday"].apply(lambda x: 1 if x == "Holiday" else 0).fillna(0)

# ðŸ“Œ å¤–ã‚Œå€¤ã®é™¤åŽ»ï¼ˆIQRã‚’ä½¿ç”¨ï¼‰
Q1 = df_train["sales"].quantile(0.25)
Q3 = df_train["sales"].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
df_train = df_train[(df_train["sales"] >= lower_bound) & (df_train["sales"] <= upper_bound)]
#print("After outlier removal:", df_train.shape)

# ðŸ“Œ é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤
df_train.drop_duplicates(inplace=True)
df_test.drop_duplicates(inplace=True)

# ðŸ“Œ æœ€çµ‚ç¢ºèª
# print(df_train.head())
# print(df_train.info())
# print(df_test.head())
# print(df_test.info())

# print(df_train.columns)  # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å­˜åœ¨ã™ã‚‹ã‚«ãƒ©ãƒ ä¸€è¦§ã‚’ç¢ºèª

# if df_train.empty:
#     print("âš  df_train is empty! Check preprocessing steps.")
# else:
#     print(df_train.head())

import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error

from sklearn.metrics import mean_squared_log_error

# ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®è¨­å®š
features = [
    "store_encoded", "family_encoded", "day_of_week", "month", "year", "is_weekend", 
    "dcoilwtico", "transactions", "is_holiday"
] + [col for col in df_train.columns if "type_store_" in col or "cluster_" in col] + [
    "lag_7", "lag_14", "lag_30", "rolling_mean_7", "rolling_mean_14", "rolling_mean_30"
]

target = "sales"

# æ¬ æå€¤ã®å‡¦ç†ï¼ˆXGBoostã¯æ¬ æå€¤ã‚’è‡ªå‹•å‡¦ç†ã™ã‚‹ãŒã€è£œå®Œã—ã¦ãŠãï¼‰
df_train.fillna(0, inplace=True)
df_test.fillna(0, inplace=True)

# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
X_train, X_valid, y_train, y_valid = train_test_split(
    df_train[features], df_train[target], test_size=0.2, random_state=42
)

# XGBoost ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ
dtrain = xgb.DMatrix(X_train, label=y_train)
dvalid = xgb.DMatrix(X_valid, label=y_valid)
dtest = xgb.DMatrix(df_test[features])

# XGBoost ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
params = {
    "objective": "reg:squarederror",  # å›žå¸°å•é¡Œ
    "eval_metric": "mae",  # è©•ä¾¡æŒ‡æ¨™ï¼ˆMAE: Mean Absolute Errorï¼‰
    "learning_rate": 0.1,
    "max_depth": 6,
    "subsample": 0.8,
    "colsample_bytree": 0.8,
    "seed": 42
}

# ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
watchlist = [(dtrain, "train"), (dvalid, "valid")]
model = xgb.train(params, dtrain, num_boost_round=500, evals=watchlist, early_stopping_rounds=50, verbose_eval=50)

# äºˆæ¸¬
predictions = model.predict(dtest)

# çµæžœã®ä¿å­˜
df_test["sales_predictions"] = predictions
df_test[["id", "sales_predictions"]].to_csv("submission.csv", index=False)

# æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡
y_valid_pred = model.predict(dvalid)
y_valid_pred = np.maximum(0, y_valid_pred)# è² ã®å€¤ã‚’0ã«ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
rmsle = np.sqrt(mean_squared_log_error(y_valid, y_valid_pred))
print(f"Validation RMSLE: {rmsle:.4f}")